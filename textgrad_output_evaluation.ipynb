{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058585b9-2412-476b-868f-31872bf66c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langfun as lf\n",
    "import pyglove as pg\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import os\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # reads .env in project root directory\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec06f22-0d7c-4f96-bc6f-e22c5a3fda71",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400ba739-c58f-40e1-8983-56b3b07888d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace some utility functions to enable pdf encoding in textgrad\n",
    "\n",
    "def is_pdf(data):\n",
    "    \"\"\"\n",
    "    Checks if the given data starts with the PDF file signature.\n",
    "\n",
    "    :param data: bytes object, the file data to check\n",
    "    :return: True if it's a PDF file, otherwise False\n",
    "    \"\"\"\n",
    "    pdf_signature = b'%PDF-'\n",
    "    return data.startswith(pdf_signature)\n",
    "\n",
    "from textgrad.engine_experimental.engine_utils import *\n",
    "import textgrad.engine_experimental.engine_utils\n",
    "from typing import List, Union\n",
    "\n",
    "def new_get_image_type_from_bytes(data):\n",
    "    if is_jpeg(data):\n",
    "        return \"jpeg\"\n",
    "    elif is_png(data):\n",
    "        return \"png\"\n",
    "    elif is_pdf(data):\n",
    "        return \"pdf\"\n",
    "    else:\n",
    "        raise ValueError(\"Image type not supported, only jpeg and png supported.\")\n",
    "\n",
    "def format_content_anthropic(content: List[Union[str, bytes]]) -> List[dict]:\n",
    "    \"\"\"Helper function to format a list of strings and bytes into a list of dictionaries to pass as messages to the API.\n",
    "    \"\"\"\n",
    "    formatted_content = []\n",
    "    for item in content:\n",
    "        if isinstance(item, bytes):\n",
    "            # For now, bytes are assumed to be images\n",
    "            image_type = new_get_image_type_from_bytes(item)\n",
    "            base64_image = base64.b64encode(item).decode('utf-8')\n",
    "            if image_type =='pdf':\n",
    "                formatted_content.append({\n",
    "                \"type\": \"document\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"application/pdf\",\n",
    "                    \"data\": base64_image\n",
    "            }\n",
    "                })\n",
    "            else:\n",
    "                formatted_content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image_type,\n",
    "                        \"data\": base64_image,\n",
    "                    },\n",
    "                })\n",
    "        elif isinstance(item, str):\n",
    "            formatted_content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": item\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input type: {type(item)}\")\n",
    "    return formatted_content\n",
    "\n",
    "# textgrad.engine_experimental.engine_utils.open_ai_like_formatting = _format_content_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a12da",
   "metadata": {},
   "source": [
    "# Output Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8ade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Read the PDF file and extract the following parameters for all high-entropy alloys discussed in the results section:\n",
    "\n",
    "1. name (string, e.g., \"AlCoCrFeNi\")\n",
    "2. nominal_composition (string, representing the stoichiometric ratio of each element, e.g., \"Al1.0Co1.0Cr1.0Fe1.0Ni1.0\". If an element's ratio is not explicitly stated, assume 1.0)\n",
    "3. measured_composition (string, exactly as written in the paper)\n",
    "4. lattice_constant (float, in angstroms, rounded to 3 decimal places)\n",
    "5. phases (string, e.g., \"BCC\")\n",
    "6. alloy_condition (string, e.g., \"As-Cast\")\n",
    "7. doi (string)\n",
    "\n",
    "Extract parameters primarily from the text. Use data from tables only if the text data is incomplete. Use figures as a last resort. If a parameter is truly missing from the PDF for a given alloy, explicitly report it as \"Not found\" rather than omitting it.\n",
    "\n",
    "For each parameter, include a confidence score (0-100) indicating your certainty in the extracted information. Consider a score of 90 or above as high confidence.\n",
    "\n",
    "The output should be a list of JSON objects, one for each alloy discussed in the paper, in the following format:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"name\": \"AlloyName\",\n",
    "        \"nominal_composition\": \"Element11.0Element21.0...\",\n",
    "        \"measured_composition\": \"Composition as written\",\n",
    "        \"lattice_constant\": X.XXX,\n",
    "        \"phases\": \"Phase1,Phase2,...\",\n",
    "        \"alloy_condition\": \"condition\",\n",
    "        \"doi\": \"DOI\",\n",
    "        \"confidence_scores\": {\n",
    "            \"name\": XX,\n",
    "            \"nominal_composition\": XX,\n",
    "            \"measured_composition\": XX,\n",
    "            \"lattice_constant\": XX,\n",
    "            \"phases\": XX,\n",
    "            \"alloy_condition\": XX,\n",
    "            \"doi\": XX\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\n",
    "Include an alloy in the output only if it is explicitly discussed in the results section. Ensure that the output format and data closely match the provided schema. If information for a specific parameter is not available, use \"Not found\" and assign a low confidence score.\n",
    "\n",
    "Example of correct output:\n",
    "[\n",
    "    {\n",
    "        \"name\": \"HfNbTaTiZr\",\n",
    "        \"nominal_composition\": \"Hf1.0Nb1.0Ta1.0Ti1.0Zr1.0\",\n",
    "        \"measured_composition\": \"Hf20.8Nb18.9Ta20.2Ti20.2Zr19.9\",\n",
    "        \"lattice_constant\": 3.414,\n",
    "        \"phases\": \"BCC\",\n",
    "        \"alloy_condition\": \"As-Cast\",\n",
    "        \"doi\": \"10.1016/j.jallcom.2014.11.064\",\n",
    "        \"confidence_scores\": {\n",
    "            \"name\": 100,\n",
    "            \"nominal_composition\": 90,\n",
    "            \"measured_composition\": 95,\n",
    "            \"lattice_constant\": 100,\n",
    "            \"phases\": 100,\n",
    "            \"alloy_condition\": 95,\n",
    "            \"doi\": 100\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "Example of output with missing data:\n",
    "[\n",
    "    {\n",
    "        \"name\": \"AlCoCrFeNi\",\n",
    "        \"nominal_composition\": \"Al1.0Co1.0Cr1.0Fe1.0Ni1.0\",\n",
    "        \"measured_composition\": \"Not found\",\n",
    "        \"lattice_constant\": 3.567,\n",
    "        \"phases\": \"FCC\",\n",
    "        \"alloy_condition\": \"Not found\",\n",
    "        \"doi\": \"10.1016/j.example.2023.01.001\",\n",
    "        \"confidence_scores\": {\n",
    "            \"name\": 100,\n",
    "            \"nominal_composition\": 90,\n",
    "            \"measured_composition\": 0,\n",
    "            \"lattice_constant\": 95,\n",
    "            \"phases\": 100,\n",
    "            \"alloy_condition\": 0,\n",
    "            \"doi\": 100\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37edad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom loss function for PDF files\n",
    "from textgrad.engine import EngineLM, get_engine\n",
    "from textgrad.variable import Variable\n",
    "from typing import List, Union\n",
    "from textgrad.autograd import LLMCall, FormattedLLMCall, OrderedFieldsMultimodalLLMCall\n",
    "from textgrad.autograd import Module\n",
    "from textgrad.config import SingletonBackwardEngine\n",
    "\n",
    "class EvaluatePdfOutputLoss(Module):\n",
    "    def __init__(self,\n",
    "                 evaluation_instruction: str,\n",
    "                 engine: Union[EngineLM, str] = None,\n",
    "                 system_prompt: Variable = None):\n",
    "        super().__init__()\n",
    "        self.evaluation_instruction = Variable(evaluation_instruction, role_description=\"evaluation instruction\", requires_grad=False)\n",
    "        if ((engine is None) and (SingletonBackwardEngine().get_engine() is None)):\n",
    "            raise Exception(\"No engine provided. Either provide an engine as the argument to this call, or use `textgrad.set_backward_engine(engine)` to set the backward engine.\")\n",
    "        elif engine is None:\n",
    "            engine = SingletonBackwardEngine().get_engine()\n",
    "        if isinstance(engine, str):\n",
    "            engine = get_engine(engine)\n",
    "        self.engine = engine\n",
    "        if system_prompt:\n",
    "            self.system_prompt = system_prompt\n",
    "        else:\n",
    "            self.system_prompt = Variable(\"You are an evaluation system that evaluates the correctness of knowledge extraction tasks from scientific papers.\",\n",
    "                                            requires_grad=False,\n",
    "                                            role_description=\"system prompt for the evaluation\")\n",
    "\n",
    "        self.multimodal_llm_call = OrderedFieldsMultimodalLLMCall(engine=self.engine,\n",
    "                                                                  system_prompt=self.system_prompt,\n",
    "                                                                  fields=[\"Evaluation Instruction\", \"Question\", \"Image\", \"Answer\"])\n",
    "\n",
    "    def forward(self, image: Variable, question: Variable, response: Variable) -> Variable:\n",
    "        \n",
    "        inputs = {\n",
    "            \"Evaluation Instruction\": self.evaluation_instruction,\n",
    "            \"Question\": question,\n",
    "            \"Image\": image,\n",
    "            \"Answer\": response\n",
    "        }\n",
    "        return self.multimodal_llm_call(inputs=inputs,\n",
    "                                        response_role_description=f\"evaluation of the {response.get_role_description()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7058f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad.engine_experimental.litellm import LiteLLMEngine\n",
    "import textgrad as tg\n",
    "\n",
    "# llm_engine = LiteLLMEngine(\"gemini/gemini-1.5-flash\", cache=False,is_multimodal=True)\n",
    "# llm_backward_engine = LiteLLMEngine(\"gemini/gemini-1.5-flash\", cache=False,is_multimodal=True)\n",
    "# tg.set_backward_engine(llm_backward_engine, override=True)\n",
    "\n",
    "llm_engine = get_engine(\"claude-3-5-sonnet-20240620\")\n",
    "llm_backward_engine = get_engine(\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "llm_engine._format_content = format_content_anthropic\n",
    "llm_backward_engine._format_content = format_content_anthropic\n",
    "# tg.set_backward_engine(llm_engine, override=True)\n",
    "tg.set_backward_engine(llm_backward_engine, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390d37c-e198-45e1-a80f-c4f49d51aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_instruction = \"\"\"Below is the output from a data extraction task for a given PDF file, and the PDF itself.\n",
    "You need to evaluate the output according to the provided PDF for each extracted material, be super concise:\n",
    "Does the output matches the format provided in the question? Answer yes or no.\n",
    "Are the extract material high-entropy alloys? Answer yes or no.\n",
    "Are the alloy composition in the output correct and reflect the material? Answer yes or no.\n",
    "Are the lattice constants value in the output formatted in angstrom? Answer yes or no.\n",
    "Are the lattice constants in the output truly the lattice constant of the material not others? Answer yes or no.\n",
    "Are the phase information in the output correct and reflect the material? Answer yes or no.\n",
    "Are the alloy condition in the output correct and reflect the material? Answer yes or no.\n",
    "Is the DOI in the output matches with the original paper? Answer yes or no.\n",
    "Is there any HEA high-entropy alloys missed in the provided ouput? yes or no.\n",
    "\"\"\"\n",
    "eval_instruction = tg.Variable(evaluation_instruction, requires_grad=False, role_description=\"evaluation instruction for the task\")\n",
    "eval_fn = EvaluatePdfOutputLoss(evaluation_instruction=evaluation_instruction,engine=llm_engine)\n",
    "\n",
    "# question = tg.Variable(start_prompt,requires_grad=True,role_description=\"question input for the PDF file\")\n",
    "question = tg.Variable(prompt,requires_grad=False,role_description=\"question input for the PDF file\")\n",
    "\n",
    "# optimizer = tg.TGD(parameters=[question],engine=llm_backward_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83f9e24-e2cf-4422-aa59-48a2cc9b04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_json_and_pdf(json_path: Path):\n",
    "    \"\"\"Load a JSON file as text and its corresponding PDF using lf.PDF\"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_text = f.read()\n",
    "\n",
    "    pdf_path = json_path.with_suffix(\".pdf\")\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"⚠️ PDF missing for {json_path.name}\")\n",
    "        return None\n",
    "\n",
    "    pdf_doc = lf.PDF(str(pdf_path))\n",
    "    return json_text, pdf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc5d276-1554-413d-90f9-6f6511a5817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from pathlib import Path\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# ---------- fast, safe scanners ----------\n",
    "def _scan_balanced(text: str, opener: str, closer: str, start_idx: int = 0):\n",
    "    \"\"\"\n",
    "    Return (start,end) of the first balanced JSON chunk from the first opener found\n",
    "    at or after start_idx. Handles strings and escapes. Returns None if not found.\n",
    "    \"\"\"\n",
    "    i = text.find(opener, start_idx)\n",
    "    if i == -1:\n",
    "        return None\n",
    "    depth = 0\n",
    "    in_str = False\n",
    "    esc = False\n",
    "    quote = None\n",
    "    for j in range(i, len(text)):\n",
    "        ch = text[j]\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == \"\\\\\":\n",
    "                esc = True\n",
    "            elif ch == quote:\n",
    "                in_str = False\n",
    "            # stay inside string\n",
    "            continue\n",
    "        else:\n",
    "            if ch in ('\"', \"'\"):\n",
    "                in_str = True\n",
    "                quote = ch\n",
    "            elif ch == opener:\n",
    "                depth += 1\n",
    "            elif ch == closer:\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    return (i, j + 1)\n",
    "    return None  # unbalanced\n",
    "\n",
    "def _find_all_top_level(text: str, opener: str, closer: str, max_items: int = 2):\n",
    "    \"\"\"Yield up to max_items balanced chunks (substrings) for the given bracket type.\"\"\"\n",
    "    pos = 0\n",
    "    found = 0\n",
    "    while found < max_items:\n",
    "        rng = _scan_balanced(text, opener, closer, start_idx=pos)\n",
    "        if rng is None:\n",
    "            break\n",
    "        s, e = rng\n",
    "        yield text[s:e]\n",
    "        found += 1\n",
    "        pos = e\n",
    "\n",
    "# ---------- candidate extraction ----------\n",
    "_FENCE_JSON_RE = re.compile(r\"```json\\s*(.*?)```\", re.DOTALL | re.IGNORECASE)\n",
    "_FENCE_ANY_RE  = re.compile(r\"```(?!json)(?:[a-zA-Z0-9_+-]*)\\s*(.*?)```\", re.DOTALL)\n",
    "\n",
    "def _extract_json_candidates(text: str, max_candidates: int = 6):\n",
    "    # 1) ```json fenced blocks (fast + accurate)\n",
    "    for m in _FENCE_JSON_RE.finditer(text):\n",
    "        yield m.group(1).strip()\n",
    "    # 2) other fenced blocks (sometimes people put JSON in ```text)\n",
    "    for m in _FENCE_ANY_RE.finditer(text):\n",
    "        yield m.group(1).strip()\n",
    "    # 3) top-level arrays and objects via balanced scan (no regex backtracking)\n",
    "    for chunk in _find_all_top_level(text, \"[\", \"]\", max_items=2):\n",
    "        yield chunk.strip()\n",
    "    for chunk in _find_all_top_level(text, \"{\", \"}\", max_items=2):\n",
    "        yield chunk.strip()\n",
    "\n",
    "def _light_fix_json(text: str) -> str:\n",
    "    # very light fixes: remove trailing commas; swap single->double quotes in simple cases\n",
    "    import re\n",
    "    fixed = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", text)\n",
    "    fixed = re.sub(r\"(?P<prefix>{|\\[|,)\\s*'(?P<key>[^'\\\\]*?)'\\s*:\", lambda m: f'{m.group(\"prefix\")} \"{m.group(\"key\")}\":', fixed)\n",
    "    fixed = re.sub(r\":\\s*'(?P<val>[^'\\\\]*?)'(\\s*[,}\\]])\", lambda m: f': \"{m.group(\"val\")}\"{m.group(2)}', fixed)\n",
    "    return fixed\n",
    "\n",
    "def response_to_json(response: str, filename: str):\n",
    "    \"\"\"\n",
    "    Extract the first valid JSON from `response` and save to <filename>.optimized.json.\n",
    "    Uses balanced scanning (no catastrophic regex).\n",
    "    \"\"\"\n",
    "    out_base = Path(filename)\n",
    "    out_json = out_base.with_suffix(\"\").with_name(out_base.stem + \".optimized.json\")\n",
    "    out_raw  = out_base.with_suffix(\"\").with_name(out_base.stem + \"_raw.txt\")\n",
    "\n",
    "    tried = 0\n",
    "    for cand in _extract_json_candidates(response):\n",
    "        tried += 1\n",
    "        # Try strict parse\n",
    "        try:\n",
    "            obj = json.loads(cand)\n",
    "            out_json.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            print(f\"✅ Parsed candidate #{tried} (strict). Saved to {out_json}\")\n",
    "            return obj\n",
    "        except JSONDecodeError:\n",
    "            pass\n",
    "        # Try light fix\n",
    "        try:\n",
    "            fixed = _light_fix_json(cand)\n",
    "            obj = json.loads(fixed)\n",
    "            out_json.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            print(f\"✅ Parsed candidate #{tried} after light fix. Saved to {out_json}\")\n",
    "            return obj\n",
    "        except JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "    # Nothing worked — save raw once for inspection\n",
    "    out_raw.write_text(response, encoding=\"utf-8\")\n",
    "    print(f\"⚠️ No valid JSON found after {tried} candidates. Raw saved to {out_raw}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8abae2df-531b-479f-8325-407fea9dba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 JSON files\n",
      "I'll evaluate the output for each extracted material according to the provided criteria:\n",
      "\n",
      "1. Does the output match the format provided in the question?\n",
      "Yes. The output is a list of JSON objects with the required fields.\n",
      "\n",
      "2. Are the extracted materials high-entropy alloys?\n",
      "Yes. All extracted alloys are high-entropy alloys from the CoFeNiMnTixAl1-x system.\n",
      "\n",
      "3. Are the alloy compositions in the output correct and reflect the material?\n",
      "Yes. The compositions match those given in the paper for each alloy.\n",
      "\n",
      "4. Are the lattice constants value in the output formatted in angstrom?\n",
      "Yes. The lattice constants are given in angstroms.\n",
      "\n",
      "5. Are the lattice constants in the output truly the lattice constant of the material not others?\n",
      "Yes. The lattice constants match those reported in the paper for the BCC phase.\n",
      "\n",
      "6. Are the phase information in the output correct and reflect the material?\n",
      "Yes. The phase information matches what is reported in the paper for each composition.\n",
      "\n",
      "7. Are the alloy conditions in the output correct and reflect the material?\n",
      "Yes. The alloys are reported as \"As-Cast\" which matches the paper.\n",
      "\n",
      "8. Is the DOI in the output matches with the original paper?\n",
      "Yes. The DOI matches the one given in the paper.\n",
      "\n",
      "9. Is there any HEA high-entropy alloys missed in the provided output?\n",
      "Yes. The output is missing some of the intermediate compositions discussed in the paper, such as Ti0.1Al0.9, Ti0.3Al0.7, and Ti0.8Al0.2.\n",
      "✅ Parsed candidate #1 (strict). Saved to doi_1386.optimized.json\n"
     ]
    }
   ],
   "source": [
    "# set your folder path\n",
    "import time\n",
    "folder = Path(\"./\")\n",
    "json_files = list(folder.glob(\"*.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files\")\n",
    "\n",
    "for json_path in json_files:\n",
    "    json_text, pdf_to_read_lf = load_json_and_pdf(json_path)\n",
    "\n",
    "    response = tg.Variable(json_text, requires_grad=True, role_description=\"solution to the data extraction task\")\n",
    "    pdf_bytes = pdf_to_read_lf.to_bytes()\n",
    "    pdf_image = tg.Variable(pdf_bytes, requires_grad=False, role_description=\"PDF file of a research paper\")\n",
    "    optimizer = tg.TGD(parameters=[response],engine=llm_backward_engine)\n",
    "    loss = eval_fn(question=question, image = pdf_image, response=response)\n",
    "    print(loss.value)\n",
    "    loss_file = json_path.with_suffix(\".txt\")\n",
    "    with open(loss_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(str(loss.value))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(response.value)\n",
    "    response_to_json(response=response.value,filename=json_path.stem)\n",
    "    optimizer.zero_grad()\n",
    "    # break\n",
    "    # time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
